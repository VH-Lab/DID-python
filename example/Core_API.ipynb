{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did/example/Core_API\n",
    "#   v0.0.0\n",
    "#   Purpose: to demonstrate the key features of the DID API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This adds the path to import the development version (git repo) of DID Python.\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic DID imports.\n",
    "from did import DID, DIDDocument, Query as Q\n",
    "from did.database import SQL\n",
    "\n",
    "from did.exception import IntegrityError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python built in libraries binary data storage demo.\n",
    "import numpy as np\n",
    "import struct\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DID instance is initialized with \n",
    "#   a DID database, which inherits from the DID_Database abstract class,\n",
    "#   a path to a directory where the binary data lives,\n",
    "#   and the optional argument `auto_save`, which defaults to False.\n",
    "did = DID(\n",
    "    driver = SQL(\n",
    "        'postgres://postgres:password@localhost:5432/did_tests',\n",
    "        \n",
    "        hard_reset_on_init = True,\n",
    "        debug_mode = False,\n",
    "        verbose_feedback = True,\n",
    "    ),\n",
    "    binary_directory = './test_sql_crud',\n",
    "    \n",
    "    auto_save = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `DIDDocument` objects are wrappers for DID documents,\n",
    "#   which are JSON data structured by NDI schema.\n",
    "# `DIDDocument`s are initialized by passing in that JSON structure.\n",
    "\n",
    "# Here, we set up three DID documents and initialize them.\n",
    "mock_document_data = [\n",
    "    {\n",
    "        'base': {\n",
    "            'id': '0',\n",
    "            'session_id': '2387492',\n",
    "            'name': 'A',\n",
    "            'datestamp': '2020-10-28T08:12:20+0000',\n",
    "            'snapshots': [],\n",
    "            'records': [],\n",
    "        },\n",
    "        'depends_on': [],\n",
    "        'dependencies': [],\n",
    "        'binary_files': [],\n",
    "        'document_class': {\n",
    "            'definition': '$NDIDOCUMENTPATH/ndi_document_app.json',\n",
    "            'validation': '$NDISCHEMAPATH/ndi_document_app_schema.json',\n",
    "            'class_name': 'ndi_document_app',\n",
    "            'property_list_name': 'app',\n",
    "            'class_version': 1,\n",
    "            'superclasses': [{\n",
    "                'definition': '$NDIDOCUMENTPATH/base_document.json'\n",
    "            }],\n",
    "        },\n",
    "        'app': {\n",
    "            'a': True,\n",
    "            'b': True\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'base': {\n",
    "            'id': '1',\n",
    "            'session_id': '2387492',\n",
    "            'name': 'B',\n",
    "            'datestamp': '2020-10-28T08:12:20+0000',\n",
    "            'snapshots': [],\n",
    "            'records': [],\n",
    "        },\n",
    "        'depends_on': [],\n",
    "        'dependencies': [],\n",
    "        'binary_files': [],\n",
    "        'document_class': {\n",
    "            'definition': '$NDIDOCUMENTPATH/ndi_document_app.json',\n",
    "            'validation': '$NDISCHEMAPATH/ndi_document_app_schema.json',\n",
    "            'class_name': 'ndi_document_app',\n",
    "            'property_list_name': 'app',\n",
    "            'class_version': 1,\n",
    "            'superclasses': [{\n",
    "                'definition': '$NDIDOCUMENTPATH/base_document.json'\n",
    "            }],\n",
    "        },\n",
    "        'app': {\n",
    "            'a': True,\n",
    "            'b': False\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'base': {\n",
    "            'id': '2',\n",
    "            'session_id': '2387492',\n",
    "            'name': 'C',\n",
    "            'datestamp': '2020-10-28T08:12:20+0000',\n",
    "            'snapshots': [],\n",
    "            'records': [],\n",
    "        },\n",
    "        'depends_on': [],\n",
    "        'dependencies': [],\n",
    "        'binary_files': [],\n",
    "        'document_class': {\n",
    "            'definition': '$NDIDOCUMENTPATH/ndi_document_app.json',\n",
    "            'validation': '$NDISCHEMAPATH/ndi_document_app_schema.json',\n",
    "            'class_name': 'ndi_document_app',\n",
    "            'property_list_name': 'app',\n",
    "            'class_version': 1,\n",
    "            'superclasses': [{\n",
    "                'definition': '$NDIDOCUMENTPATH/base_document.json'\n",
    "            }],\n",
    "        },\n",
    "        'app': {\n",
    "            'a': False,\n",
    "            'b': False\n",
    "        },\n",
    "    },\n",
    "]\n",
    "def get_new_moc_docs():\n",
    "    return [DIDDocument(deepcopy(data)) for data in mock_document_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "Changes saved.\n",
      "saving...\n",
      "Changes saved.\n",
      "saving...\n",
      "Changes saved.\n"
     ]
    }
   ],
   "source": [
    "# We'll start by adding our three `DIDDocument`s to the DID instance.\n",
    "\n",
    "#   Note: Since `auto_save` has beens set to True, they are saved to the database individually.\n",
    "#         When `auto_save` is False, changes may be saved by calling DID.save().\n",
    "#         Alternatively, all methods that modify the database have the `save` keyword argument,\n",
    "#           which can be set to true or false to override `auto_save`.\n",
    "#         Saving and snapshots will be covered in futher detail below (see ## Transaction Management ##).\n",
    "\n",
    "moc_docs = get_new_moc_docs()\n",
    "for doc in moc_docs:\n",
    "    did.add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Key error for document id=0.\n"
     ]
    }
   ],
   "source": [
    "# Attempts to add duplicate `DIDDocument`s will throw an IntegrityError with useful information.\n",
    "\n",
    "try:\n",
    "    did.add(moc_docs[0])\n",
    "except IntegrityError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'name': 'A',\n",
       " 'records': ['59fce29d646cdf31ac6613a4f85e90d7f476c2eb5ddea50916d9ec6bfd2df9ca'],\n",
       " 'datestamp': '2020-10-28T08:12:20+0000',\n",
       " 'snapshots': [1],\n",
       " 'session_id': '2387492'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `DIDDocument`s can be retrieved by ID...\n",
    "\n",
    "doc = did.find_by_id(moc_docs[0].id)\n",
    "\n",
    "doc.data['base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': True, 'b': True}, {'a': True, 'b': False}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or by DID Query.\n",
    "\n",
    "by_app_a = Q('app.a') == True\n",
    "docs = did.find(by_app_a)\n",
    "\n",
    "[doc.data['app'] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More complex DID Queries may be composed with and (&) and or (|) operators,\n",
    "#   with order of operations left-to-right or as structured by parentheses.\n",
    "\n",
    "app_a_is_true = Q('app.a') == False\n",
    "app_b_is_true = Q('app.b') == False\n",
    "is_not_zero_version = Q('base.version') > '0'\n",
    "is_ndi_doc_class = Q('document_class.class_name').contains('ndi_')\n",
    "\n",
    "by_complex_query = (app_a_is_true | app_b_is_true) & is_not_zero_version & is_ndi_doc_class\n",
    "docs = did.find(by_complex_query)\n",
    "\n",
    "[doc.data for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<did.document.DIDDocument at 0x117454f40>,\n",
       " <did.document.DIDDocument at 0x117454d30>,\n",
       " <did.document.DIDDocument at 0x107a6d670>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All documents can be retrieved very simply.\n",
    "\n",
    "did.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': True, 'b': True, 'c': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `DIDDocument`s can be updated with instances at hand...\n",
    "\n",
    "# Use-cases:\n",
    "# - `DIDDocument` instance is available.\n",
    "# - Avoids need for dict `payload`.\n",
    "\n",
    "doc = moc_docs[0]\n",
    "doc.data['app']['c'] = True\n",
    "did.update(doc)\n",
    "\n",
    "doc_from_db = did.find_by_id(moc_docs[0].id)\n",
    "doc_from_db.data['app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': True, 'b': True, 'c': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# , by ID and payload...\n",
    "\n",
    "# Use-cases:\n",
    "# - `DIDDocument` instance is not available.\n",
    "# - Allows reuse of `payload`s.\n",
    "\n",
    "payload = { 'app': { 'c': False } }\n",
    "did.update_by_id(moc_docs[0].id, payload, )\n",
    "\n",
    "doc_from_db = did.find_by_id(moc_docs[0].id)\n",
    "doc_from_db.data['app']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'a': False, 'b': False},\n",
       " {'a': True, 'b': False, 'c': True, 'd': True},\n",
       " {'a': True, 'b': False, 'c': True, 'd': True}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#, or by Query and payload.\n",
    "\n",
    "# Use-cases:\n",
    "# - Multiple documents require same updates.\n",
    "# - Allows reuse of `payload`s.\n",
    "\n",
    "payload = {\n",
    "    'app': {\n",
    "        'b': False,\n",
    "        'c': True,\n",
    "        'd': True,\n",
    "    },\n",
    "}\n",
    "by_app_a = Q('app.a') == True\n",
    "did.update_many(by_app_a, payload)\n",
    "\n",
    "docs_from_db = did.find()\n",
    "[doc.data['app'] for doc in docs_from_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'a': False, 'b': False},\n",
       " {'a': True, 'b': False, 'c': True, 'd': True},\n",
       " {'a': True, 'b': False, 'c': True, 'd': True},\n",
       " {'a': False, 'b': True}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you are not sure if a DID document is in the database or not,\n",
    "#   but want to update it if it is, use DID.upsert()\n",
    "# This will add the document to the database if it does not already exist...\n",
    "\n",
    "new_moc_doc = DIDDocument({\n",
    "    'base': {\n",
    "        'id': '3',\n",
    "        'session_id': '2387492',\n",
    "        'name': 'D',\n",
    "        'datestamp': '2020-10-28T08:12:20+0000',\n",
    "        'snapshots': [],\n",
    "        'records': [],\n",
    "    },\n",
    "    'depends_on': [],\n",
    "    'binary_files': [],\n",
    "    'document_class': {\n",
    "        'definition': '$NDIDOCUMENTPATH/ndi_document_app.json',\n",
    "        'validation': '$NDISCHEMAPATH/ndi_document_app_schema.json',\n",
    "        'class_name': 'ndi_document_app',\n",
    "        'property_list_name': 'app',\n",
    "        'class_version': 1,\n",
    "        'superclasses': [{\n",
    "            'definition': '$NDIDOCUMENTPATH/base_document.json'\n",
    "        }],\n",
    "    },\n",
    "    'app': {\n",
    "        'a': False,\n",
    "        'b': True\n",
    "    },\n",
    "})\n",
    "did.upsert(new_moc_doc)\n",
    "\n",
    "docs_from_db = did.find()\n",
    "[doc.data['app'] for doc in docs_from_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'a': False, 'b': False},\n",
       " {'a': True, 'b': False, 'c': True, 'd': True},\n",
       " {'a': True, 'b': False, 'c': True, 'd': True},\n",
       " {'a': False, 'b': True, 'c': False, 'd': False}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the document does exist in the database, it will be updated.\n",
    "\n",
    "new_moc_doc.data['app'] = {\n",
    "    **new_moc_doc.data['app'],\n",
    "    'c': False,\n",
    "    'd': False,\n",
    "}\n",
    "did.upsert(new_moc_doc)\n",
    "\n",
    "docs_from_db = did.find()\n",
    "[doc.data['app'] for doc in docs_from_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'a': False, 'b': False},\n",
       " {'a': True, 'b': False, 'c': True, 'd': True},\n",
       " {'a': True, 'b': False, 'c': True, 'd': True}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly to updates, `DIDDocument`s can be deleted directly...\n",
    "\n",
    "did.delete(new_moc_doc)\n",
    "\n",
    "docs_from_db = did.find()\n",
    "[doc.data['app'] for doc in docs_from_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting A\n",
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'C', 'app': {'a': False, 'b': False}},\n",
       " {'name': 'B', 'app': {'a': True, 'b': False, 'c': True, 'd': True}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#, by ID...\n",
    "\n",
    "print(f'deleting {moc_docs[0].data[\"base\"][\"name\"]}')\n",
    "did.delete_by_id(moc_docs[0].id)\n",
    "\n",
    "docs_from_db = did.find()\n",
    "[\n",
    "    {\n",
    "        'name': doc.data['base']['name'],\n",
    "        'app': doc.data['app']\n",
    "    }\n",
    "    for doc in docs_from_db\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#, or by Query.\n",
    "\n",
    "by_app_a = Q('app.b') == False\n",
    "did.delete_many(by_app_a)\n",
    "\n",
    "docs_from_db = did.find()\n",
    "[doc.data['app'] for doc in docs_from_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transaction Management ##\n",
    "\n",
    "# All CRUD operations so far have been saved by default,\n",
    "#   because the DID instance was instantiated with `auto_save = True`.\n",
    "\n",
    "# To manage calls to the database, operations can be bundled into transactions (working_snapshots).\n",
    "\n",
    "# CRUD methods that modify the database have the `save: bool` keyword parameter,\n",
    "#   and operations that are not saved will be open or be added to the current transaction.\n",
    "\n",
    "# All operations under a current transaction are passed to the database when DID.save() is called,\n",
    "#   or when a CRUD method is called with `save = True`. At this point, the working snapshot\n",
    "#   is committed to the database.\n",
    "\n",
    "# All operations under a current transaction can be discarded by calling DID.revert()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes reverted.\n"
     ]
    }
   ],
   "source": [
    "# `DIDDocument`s can be upserted, deleted, or otherwise modified,\n",
    "#   but until they are saved, they can be reverted...\n",
    "\n",
    "for doc in moc_docs:\n",
    "    did.upsert(doc, save = False)\n",
    "did.revert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the documents in the database will remain unchanged.\n",
    "\n",
    "docs_from_db = did.find()\n",
    "[doc.data['app'] for doc in docs_from_db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are currently zero documents in the database,\n",
    "#   and we've made 11 modifications to the database so far.\n",
    "# The next snapshot will be the 12th.\n",
    "did.driver.working_snapshot_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document \"A\" logs (snapshot, record):\n",
      "  --none--\n"
     ]
    }
   ],
   "source": [
    "# All documents keep logs of their records and associated snapshots.\n",
    "# Records are hashes of a document's data\n",
    "#   at the time of it's most recent modification in the database.\n",
    "doc_a, doc_b, doc_c = get_new_moc_docs()\n",
    "\n",
    "def print_logs(doc):\n",
    "    print(f'document \"{doc.data[\"base\"][\"name\"]}\" logs (snapshot, record):')\n",
    "    logs = [d for d in zip(doc.data['base']['snapshots'], doc.data['base']['records'])]\n",
    "    if logs:\n",
    "        for log in logs:\n",
    "            print(f'  {log}')\n",
    "    else:\n",
    "        print('  --none--')\n",
    "print_logs(doc_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "Changes saved.\n",
      "document \"A\" logs (snapshot, record):\n",
      "  (12, 'ebeb424cd68e42dee56ad80192617e1a3bd4a7dc6e096c0d0dd00071b5131311')\n"
     ]
    }
   ],
   "source": [
    "# When a new doc is added to the database,\n",
    "#   its records and snapshots are updated.\n",
    "# Records and snapshots are listed from latest to oldest.\n",
    "did.add(doc_a)\n",
    "\n",
    "print_logs(doc_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document \"A\" logs (snapshot, record):\n",
      "  (13, '7716ff919c3ed2e3d9df4498b61da26824a16af619ee361248327f923f8e0e64')\n",
      "  (12, 'ebeb424cd68e42dee56ad80192617e1a3bd4a7dc6e096c0d0dd00071b5131311')\n",
      "Changes saved.\n",
      "document \"A\" logs (snapshot, record):\n",
      "  (13, '63950952f87ae7f885b8cff76f57b0c979fcd7fbc78945e181a748a65265d499')\n",
      "  (12, 'ebeb424cd68e42dee56ad80192617e1a3bd4a7dc6e096c0d0dd00071b5131311')\n"
     ]
    }
   ],
   "source": [
    "# If a document is updated multiple times in a single snapshot,\n",
    "#   then only it's most recent record for that snapshot is kept.\n",
    "\n",
    "# Note that this makes records unreliable until they are snapshotted.\n",
    "\n",
    "did.update_by_id(doc_a.id, { 'app': { 'c': True } }, save=False)\n",
    "print_logs(did.find_by_id(doc_a.id))\n",
    "\n",
    "did.update_by_id(doc_a.id, { 'app': { 'c': False } }, save=True)\n",
    "doc_a = did.find_by_id(doc_a.id)\n",
    "print_logs(doc_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes saved.\n",
      "document \"A\" logs (snapshot, record):\n",
      "  (14, '46294d135bbd02e2ef1b87b4cb2b00fdd398641bfb44049298fa8528b5e740d7')\n",
      "  (13, '63950952f87ae7f885b8cff76f57b0c979fcd7fbc78945e181a748a65265d499')\n",
      "  (12, 'ebeb424cd68e42dee56ad80192617e1a3bd4a7dc6e096c0d0dd00071b5131311')\n",
      "document \"B\" logs (snapshot, record):\n",
      "  (14, 'caaf607f362011cf1fe29504ee10fbf4932b8b6539a6d85b4f97b7b5a4f1c9ca')\n",
      "document \"C\" logs (snapshot, record):\n",
      "  (14, '8631754f65e95f0a08e7751604b0d1504cc8f66bdcebd5613c7f6092e97826ee')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If multiple documents are added in a single snapshot,\n",
    "#   then that will be reflected in the logs\n",
    "for doc in (doc_a, doc_b, doc_c):\n",
    "    did.upsert(doc, save=False)\n",
    "did.save()\n",
    "[print_logs(doc) for doc in did.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The delete will trigger snapshot 15.\n",
      "\n",
      "Changes saved.\n",
      "document \"A\" logs (snapshot, record):\n",
      "  (14, '46294d135bbd02e2ef1b87b4cb2b00fdd398641bfb44049298fa8528b5e740d7')\n",
      "  (13, '63950952f87ae7f885b8cff76f57b0c979fcd7fbc78945e181a748a65265d499')\n",
      "  (12, 'ebeb424cd68e42dee56ad80192617e1a3bd4a7dc6e096c0d0dd00071b5131311')\n",
      "document \"C\" logs (snapshot, record):\n",
      "  (14, '8631754f65e95f0a08e7751604b0d1504cc8f66bdcebd5613c7f6092e97826ee')\n",
      "\n",
      "making the next snapshot 16.\n"
     ]
    }
   ],
   "source": [
    "# Deletes are modifications too, so they will create a snapshot.\n",
    "print(f'The delete will trigger snapshot {did.driver.working_snapshot_id}.\\n')\n",
    "did.delete(doc_b)\n",
    "[print_logs(doc) for doc in did.find()]\n",
    "print(f'\\nmaking the next snapshot {did.driver.working_snapshot_id}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `DIDDocument`s may have associated binary data,\n",
    "#   which is accessible through the DID instance's bin property.\n",
    "\n",
    "# The list_files utility can be used to check what binary data exists for a given `DIDDocument`.\n",
    "\n",
    "did.bin.list_files(doc_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['new_data_name']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New binary data is given a name or identifier, and passed in as as bytes.\n",
    "# Names should be in snake_case,\n",
    "#   and should not contain spaces or special characters.\n",
    "# After every write stream is closed, the database will be updated.\n",
    "# The `open_write_stream` method has a `save` keyword argument like any other database modifier.\n",
    "\n",
    "with did.bin.open_write_stream(doc_a, 'new_data_name', save=True) as write_stream:\n",
    "    write_stream.write(b'This is test data.')\n",
    "\n",
    "did.bin.list_files(doc_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('test_sql_crud/new_data_name--0-16.bin')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The new file's path is accessible, relative to the working directory.\n",
    "#   Note that the filename is composed of the document id hyphenated with the data's name,\n",
    "#     followed by '--on_' and the document's latest snapshot.\n",
    "#     <document_id>-<name>--on_<previous_snapshot>.bin\n",
    "#     On documents that haven't yet been saved, <previous_snapshot> defaults to \"NEW\".\n",
    "\n",
    "did.bin.get_filepath(doc_a, 'new_data_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'This is test data.'\n"
     ]
    }
   ],
   "source": [
    "# Binary data is accessed as a read stream.\n",
    "\n",
    "with did.bin.open_read_stream(doc_a, 'new_data_name') as read_stream:\n",
    "    print(read_stream.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['new_data_name', 'numpy_data']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate binary files can be opened by simply writing to a new name.\n",
    "\n",
    "with did.bin.open_write_stream(doc_a, 'numpy_data') as write_stream:\n",
    "    random_data = np.random.random(1_000_000)\n",
    "    \n",
    "    for x in random_data:\n",
    "        write_stream.write(struct.pack('d', x))\n",
    "\n",
    "did.bin.list_files(doc_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 items:   10, 135, 167, 173, 128,  58, 227,  63,  66, 126\n",
      "Pointer has moved to index 5.\n",
      "Ten items from index 5:                    58, 227,  63,  66, 126, 140, 231, 136, 250, 218\n",
      "All readable data matches written data: True\n"
     ]
    }
   ],
   "source": [
    "# More complex read operations are supported through standard python libraries.\n",
    "\n",
    "with did.bin.open_read_stream(doc_a, 'numpy_data') as read_stream:\n",
    "    \n",
    "    # reading a chunk of ten bytes\n",
    "    data = read_stream.read(10)\n",
    "    parsed_data = ', '.join(str(x).rjust(3, ' ') for x in data)\n",
    "    print(f'First 10 items:  {parsed_data}')\n",
    "    \n",
    "    # moving the pointer\n",
    "    read_stream.seek(5)\n",
    "    print(f'Pointer has moved to index {read_stream.tell()}.')\n",
    "    \n",
    "    # reading chunks\n",
    "    data = read_stream.read(10)\n",
    "    parsed_data = ', '.join(str(x).rjust(3, ' ') for x in data)\n",
    "    print(f'Ten items from index 5:                   {parsed_data}')\n",
    "    \n",
    "    # converting back to numpy array\n",
    "    read_stream.seek(0)\n",
    "    data = read_stream.read()\n",
    "    retrieved_data = np.frombuffer(data, dtype=float)\n",
    "    print(f'All readable data matches written data: {all(retrieved_data == random_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numpy_data']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary files can be removed as well.\n",
    "\n",
    "did.bin.remove_file(doc_a, 'new_data_name')\n",
    "\n",
    "did.bin.list_files(doc_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
